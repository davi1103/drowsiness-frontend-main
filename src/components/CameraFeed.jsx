// ============================================================
// ðŸŽ¥ COMPONENTE: CameraFeed.jsx
// ------------------------------------------------------------
// Responsable de:
//  - Inicializar la cÃ¡mara del usuario
//  - Ejecutar MediaPipe FaceMesh con detecciÃ³n en tiempo real
//  - Enviar resultados al componente padre mediante onResults()
//  - Detener la cÃ¡mara y liberar recursos al desmontar
// ============================================================

import React, { useRef, useEffect } from "react";
import { FaceMesh } from "@mediapipe/face_mesh";
import { Camera } from "@mediapipe/camera_utils";

const CameraFeed = ({ onResults }) => {
  const videoRef = useRef(null);
  const cameraRef = useRef(null);
  const faceMeshRef = useRef(null);

  // ============================================================
  // âš™ï¸ 1. InicializaciÃ³n de MediaPipe + CÃ¡mara
  // ============================================================
  useEffect(() => {
    if (!videoRef.current) return;

    // â–¸ Carga del modelo FaceMesh desde CDN (ligero y eficiente)
    const faceMesh = new FaceMesh({
      locateFile: (file) =>
        `https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/${file}`,
    });

    // ------------------------------------------------------------
    // ðŸ§  ConfiguraciÃ³n del modelo
    // ------------------------------------------------------------
    faceMesh.setOptions({
      maxNumFaces: 1,               // Detectar solo 1 rostro
      refineLandmarks: true,        // MÃ¡s precisiÃ³n sin costo significativo
      minDetectionConfidence: 0.5,
      minTrackingConfidence: 0.5,
    });

    // ------------------------------------------------------------
    // ðŸ“¤ Callback de resultados
    // ------------------------------------------------------------
    faceMesh.onResults((results) => {
      if (
        results.multiFaceLandmarks &&
        results.multiFaceLandmarks.length > 0
      ) {
        // Enviamos Ãºnicamente las landmarks del primer rostro detectado
        onResults(results.multiFaceLandmarks[0]);
      }
    });

    // ============================================================
    // ðŸ“· 2. InicializaciÃ³n de la cÃ¡mara
    // ============================================================
    const camera = new Camera(videoRef.current, {
      onFrame: async () => {
        const video = videoRef.current;
        // Asegurar que el frame es vÃ¡lido y listo antes de procesar
        if (video && video.readyState === 4) {
          await faceMesh.send({ image: video });
        }
      },
      width: 640,
      height: 480,
    });

    camera.start(); // â–¶ï¸ Inicio del streaming

    // Guardamos referencias para poder detenerlo despuÃ©s
    cameraRef.current = camera;
    faceMeshRef.current = faceMesh;

    // ============================================================
    // ðŸ§¹ 3. Cleanup â€“ LiberaciÃ³n de recursos
    // ============================================================
    return () => {
      if (cameraRef.current) {
        cameraRef.current.stop();    // Detener cÃ¡mara
        cameraRef.current = null;
      }
      if (faceMeshRef.current) {
        faceMeshRef.current.close(); // Detener modelo
        faceMeshRef.current = null;
      }
    };
  }, []);

  // ============================================================
  // ðŸŽ¬ 4. Render: elemento de video invisible
  // ------------------------------------------------------------
  // El procesamiento es local: no se guarda ni transmite video.
  // ============================================================
  return (
    <video
      ref={videoRef}
      autoPlay
      playsInline
      muted
      style={{ display: "none" }} // No se muestra al usuario
    />
  );
};

export default CameraFeed;
